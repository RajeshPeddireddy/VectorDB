{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/UV8ZpPxj0X/6UTk4gTW5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajeshPeddireddy/VectorDB/blob/main/llamaIndex_Loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/getting_started/concepts.html"
      ],
      "metadata": {
        "id": "azES_c4aUGeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading**: this refers to getting your data from where it lives – whether it’s text files, PDFs, another website, a database, or an API – into your pipeline. LlamaHub provides hundreds of connectors to choose from.\n",
        "\n",
        "\n",
        " **Loading stage**\n",
        "\n",
        "**Nodes and Documents**: A Document is a container around any data source - for instance, a PDF, an API output, or retrieve data from a database. A Node is the atomic unit of data in LlamaIndex and represents a “chunk” of a source Document. Nodes have metadata that relate them to the document they are in and to other nodes.\n",
        "\n",
        "**Connectors**: A data connector (often called a Reader) ingests data from different data sources and data formats into Documents and Nodes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6TEVkihZUN6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/root.html\n",
        "\n",
        "\n",
        "Document and Node objects are core abstractions within LlamaIndex.\n",
        "\n",
        "------------------------\n",
        "\n",
        "A Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below.\n",
        "\n",
        "metadata - a dictionary of annotations that can be appended to the text.\n",
        "\n",
        "relationships - a dictionary containing relationships to other Documents/Nodes.\n",
        "\n",
        "---------------------------------\n",
        "\n",
        "A Node represents a “chunk” of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes.\n",
        "\n",
        "Nodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to “parse” source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a “file_name” filed in the Document is propagated to every Node).\n",
        "\n"
      ],
      "metadata": {
        "id": "U-A8qnV6U83B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documents**\n",
        "\n",
        "from llama_index.core import Document, VectorStoreIndex\n",
        "\n",
        "text_list = [text1, text2, ...]\n",
        "documents = [Document(text=t) for t in text_list]\n",
        "\n",
        "# build index\n",
        "index = VectorStoreIndex.from_documents(documents)\n"
      ],
      "metadata": {
        "id": "BfdN8MkbV_HW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nodes**\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "# load documents\n",
        "...\n",
        "\n",
        "# parse nodes\n",
        "parser = SentenceSplitter()\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# build index\n",
        "index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "Ra_3tRa5WMQ3"
      }
    }
  ]
}